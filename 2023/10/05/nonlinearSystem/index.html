<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="a long way to go 💢 random process 💢 sde  In applying frequency-domain techniques to the analysis of random signals the natural approach is to Fourier transform the signals. Unfortunately the Fourier">
<meta property="og:type" content="article">
<meta property="og:title" content="Nonlinear Systems">
<meta property="og:url" content="http://example.com/2023/10/05/nonlinearSystem/index.html">
<meta property="og:site_name" content="KNOW-HOW">
<meta property="og:description" content="a long way to go 💢 random process 💢 sde  In applying frequency-domain techniques to the analysis of random signals the natural approach is to Fourier transform the signals. Unfortunately the Fourier">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/10/05/nonlinearSystem/riemann_int.png">
<meta property="og:image" content="http://example.com/2023/10/05/nonlinearSystem/image-20230702004840807.png">
<meta property="og:image" content="http://example.com/2023/10/05/nonlinearSystem/image-20230702005049938.png">
<meta property="og:image" content="http://example.com/2023/10/05/nonlinearSystem/image-20230715101317632.png">
<meta property="og:image" content="http://example.com/2023/10/05/nonlinearSystem/image-20230702094054155.png">
<meta property="og:image" content="http://example.com/2023/10/05/nonlinearSystem/image-20230702155217093.png">
<meta property="og:image" content="http://example.com/2023/10/05/nonlinearSystem/image-20230702160220762.png">
<meta property="article:published_time" content="2023-10-05T15:48:47.000Z">
<meta property="article:modified_time" content="2024-07-04T13:57:24.373Z">
<meta property="article:author" content="Guo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/10/05/nonlinearSystem/riemann_int.png">


<link rel="canonical" href="http://example.com/2023/10/05/nonlinearSystem/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2023/10/05/nonlinearSystem/","path":"2023/10/05/nonlinearSystem/","title":"Nonlinear Systems"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Nonlinear Systems | KNOW-HOW</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">KNOW-HOW</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#a-long-way-to-go"><span class="nav-number">1.</span> <span class="nav-text">a long way to go</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#phase-noise-model"><span class="nav-number">2.</span> <span class="nav-text">Phase Noise Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#general-model"><span class="nav-number">3.</span> <span class="nav-text">General Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mathematical-background"><span class="nav-number">4.</span> <span class="nav-text">mathematical background</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#linear-systems-of-odes"><span class="nav-number">5.</span> <span class="nav-text">Linear systems of ODEs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#exact-equations"><span class="nav-number">6.</span> <span class="nav-text">Exact equations</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#integrating-factor"><span class="nav-number">7.</span> <span class="nav-text">integrating factor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nonlinear-autonomous-systems-of-odes"><span class="nav-number">8.</span> <span class="nav-text">Nonlinear Autonomous
Systems of ODEs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#critical-points"><span class="nav-number">9.</span> <span class="nav-text">critical points</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#linearization"><span class="nav-number">10.</span> <span class="nav-text">Linearization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conservative-equations"><span class="nav-number">11.</span> <span class="nav-text">Conservative equations</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hamiltonian-systems"><span class="nav-number">12.</span> <span class="nav-text">Hamiltonian Systems</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#limit-cycles"><span class="nav-number">13.</span> <span class="nav-text">Limit cycles</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#poincar%C3%A9bendixson-theorem"><span class="nav-number">14.</span> <span class="nav-text">Poincaré–Bendixson Theorem</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mathieus-equation"><span class="nav-number">15.</span> <span class="nav-text">Mathieu&#39;s equation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#floquet-theory"><span class="nav-number">16.</span> <span class="nav-text">Floquet Theory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#chaos"><span class="nav-number">17.</span> <span class="nav-text">Chaos</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#riemann-integral"><span class="nav-number">18.</span> <span class="nav-text">Riemann integral</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lebesgue-integral"><span class="nav-number">19.</span> <span class="nav-text">Lebesgue integral</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#measure-and-probabilities"><span class="nav-number">20.</span> <span class="nav-text">Measure and Probabilities</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#power-set"><span class="nav-number">21.</span> <span class="nav-text">power set</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sigma-algebra"><span class="nav-number">22.</span> <span class="nav-text">\(\sigma\)-Algebra</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#measurable-space"><span class="nav-number">23.</span> <span class="nav-text">measurable space</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#probability-space"><span class="nav-number">24.</span> <span class="nav-text">probability space</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#filtration-and-information-flow"><span class="nav-number">25.</span> <span class="nav-text">filtration and information
flow</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#martingale"><span class="nav-number">26.</span> <span class="nav-text">martingale</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#wss-process"><span class="nav-number">27.</span> <span class="nav-text">WSS process</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#autocorrelation"><span class="nav-number">28.</span> <span class="nav-text">autocorrelation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#temporal-average"><span class="nav-number">29.</span> <span class="nav-text">temporal average</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#power-spectral-density"><span class="nav-number">30.</span> <span class="nav-text">power spectral density</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#time-domain"><span class="nav-number">30.1.</span> <span class="nav-text">time domain</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#frequency-domain"><span class="nav-number">31.</span> <span class="nav-text">frequency domain</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#einstein-wiener-khinchin-theorem"><span class="nav-number">32.</span> <span class="nav-text">Einstein-Wiener-Khinchin
Theorem</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#wiener-process-or-brownian-motion"><span class="nav-number">33.</span> <span class="nav-text">Wiener Process (or Brownian
Motion)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ito-sde-with-brownian-motion"><span class="nav-number">34.</span> <span class="nav-text">Ito SDE with Brownian Motion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#stochastic-differential-equation-sde"><span class="nav-number">35.</span> <span class="nav-text">stochastic differential
equation (SDE)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#wiener-stochastic-integral"><span class="nav-number">36.</span> <span class="nav-text">Wiener Stochastic Integral</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ito-stochastic-integral"><span class="nav-number">37.</span> <span class="nav-text">Ito Stochastic Integral</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#quadratic-variation"><span class="nav-number">38.</span> <span class="nav-text">quadratic variation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#basic-ito-formula"><span class="nav-number">39.</span> <span class="nav-text">Basic Ito formula</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ito-processes"><span class="nav-number">40.</span> <span class="nav-text">Ito processes</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ito-formula-for-ito-processes"><span class="nav-number">41.</span> <span class="nav-text">Ito formula for Ito
processes</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bivariate-ito-formula"><span class="nav-number">42.</span> <span class="nav-text">Bivariate Ito formula</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ito-multiplication-table"><span class="nav-number">43.</span> <span class="nav-text">Ito multiplication table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ito-formula-using-ito-multiplication-table"><span class="nav-number">44.</span> <span class="nav-text">Ito formula using
Ito multiplication table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#solving-a-geometric-brownian-motion"><span class="nav-number">45.</span> <span class="nav-text">Solving a Geometric
Brownian Motion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#geometric-brownian-motion-gbm"><span class="nav-number">46.</span> <span class="nav-text">Geometric Brownian motion
(GBM)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#solving-step-by-step"><span class="nav-number">47.</span> <span class="nav-text">solving step by step</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#paper"><span class="nav-number">48.</span> <span class="nav-text">paper</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#book"><span class="nav-number">49.</span> <span class="nav-text">book</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#measure-theoretic-probability-theory"><span class="nav-number">50.</span> <span class="nav-text">measure-theoretic
probability theory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#blogs"><span class="nav-number">51.</span> <span class="nav-text">blogs</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Guo</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">169</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/raytroop" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;raytroop" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:raytroop@gmail.com" title="E-Mail → mailto:raytroop@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/05/nonlinearSystem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Guo">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KNOW-HOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Nonlinear Systems | KNOW-HOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Nonlinear Systems
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-05 15:48:47" itemprop="dateCreated datePublished" datetime="2023-10-05T15:48:47+00:00">2023-10-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-04 13:57:24" itemprop="dateModified" datetime="2024-07-04T13:57:24+00:00">2024-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/noise/" itemprop="url" rel="index"><span itemprop="name">noise</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="a-long-way-to-go">a long way to go</h2>
<p>💢 random process</p>
<p>💢 sde</p>
<hr />
<p>In applying frequency-domain techniques to the analysis of random
signals the natural approach is to Fourier transform the signals.</p>
<p>Unfortunately the Fourier transform of a stochastic process does not,
strictly speaking, exist because it has infinite signal energy.</p>
<h2 id="phase-noise-model">Phase Noise Model</h2>
<p>Consider a stable periodic oscillator subjected to random
fluctuations, so that is satisfies a vector Ito stochastic differential
equation of the form</p>
<p><span class="math display">\[
dX = \mathbf{f(X)}dt + G(X)dW
\]</span></p>
<h2 id="general-model">General Model</h2>
<p>Two assumptions:</p>
<ul>
<li><p>random trajectory perturbations in directions tangent to the
isochron surface passing through <span
class="math inline">\(X(t)\)</span> will never accumulate</p></li>
<li><p>random fluctuations in the direction of the tangent to the stable
orbit accumulate</p></li>
</ul>
<p>This suggests therefore the approximation</p>
<p><span class="math display">\[
X(t) \simeq \mathbf{x}_c(t+\alpha(t)) + \mathbf{\Delta}(t)
\]</span></p>
<p>where <span class="math inline">\(\mathbf{\Delta}(t)\)</span>
represents a small perturbation belonging to the tangent space to the
isochron surface pass through <span
class="math inline">\(\mathbf{x}_c(t+\alpha(t))\)</span></p>
<p>If <span class="math inline">\(\phi(X(t))\)</span> is the asymptotic
phase corresponding to trajectory point <span
class="math inline">\(X(t)\)</span>, the <strong>phase
noise</strong></p>
<p><span class="math display">\[
\alpha(t) = \phi(X(t)) - t
\]</span></p>
<p>After rigorous Ito's process, it can be proven that the phase noise
<span class="math inline">\(\alpha(t)\)</span> satisfies the scalar Ito
stochastic differential equation</p>
<p><span class="math display">\[
d\alpha(t) =
\mathbf{q}_1^T(t+\alpha(t))G(\mathbf{x}_c(t+\alpha(t)))dW(t)
\]</span></p>
<p>The equation models the <em>unwrapped</em> phase noise <span
class="math inline">\(\alpha(t)\)</span>, which takes values in <span
class="math inline">\(\mathbb{R}\)</span></p>
<blockquote>
<p><span class="math inline">\(d\alpha(t) =
\mathbf{q}_1^T(t+\alpha(t))G(\mathbf{x}_c(t+\alpha(t)))dW(t)\)</span>
can be seen as the perturbation <span
class="math inline">\(G(\mathbf{x}_c(t+\alpha(t)))dW(t)\)</span>
projected onto phase gradient <span
class="math inline">\(\mathbf{q}_1\)</span></p>
</blockquote>
<h2 id="mathematical-background">mathematical background</h2>
<h2 id="linear-systems-of-odes">Linear systems of ODEs</h2>
<h2 id="exact-equations">Exact equations</h2>
<p>Suppose <span class="math inline">\(F(x; y)\)</span> is a function of
two variables, which we call the <strong>potential function</strong>,
which suggest potential energy, or electric potential (<span
class="math inline">\(F(x; y) = C\)</span>).</p>
<p>We take the <em>total derivative</em> of <span
class="math inline">\(F\)</span>: <span class="math display">\[
dF = \frac{\partial F}{\partial x}dx +\frac{\partial F}{\partial y}dy
\]</span> We apply the total derivative to <span
class="math inline">\(F(x; y) = C\)</span>, to find the differential
equation <span class="math inline">\(dF=0\)</span></p>
<p>An equation of the form <span class="math display">\[
M(x,y)+N(x,y)\frac{dy}{dx}=0
\]</span> is called <strong>exact</strong> if it was obtained as <span
class="math inline">\(dF = 0\)</span> for some <em>potential
function</em> <span class="math inline">\(F\)</span></p>
<h2 id="integrating-factor">integrating factor</h2>
<p>Given a linear first order equation: <span class="math display">\[
y&#39;+p(x)y = f(x)
\]</span> The <strong>integrating factor</strong> is defined as <span
class="math display">\[
r(x) = e^{\int p(x)dx}
\]</span> We multiply the above linear first order equation with <span
class="math inline">\(r(x)\)</span> <span
class="math display">\[\begin{align}
y&#39;+p(x)y &amp;= f(x) \\
e^{\int p(x)dx}y&#39;+e^{\int p(x)dx}p(x)y &amp;=e^{\int p(x)dx}f(x) \\
\frac{d}{dx}\left[e^{\int p(x)dx}y\right] &amp;=e^{\int p(x)dx}f(x) \\
e^{\int p(x)dx}y &amp;= \int e^{\int p(x)dx}f(x)dx + C \\
y &amp;= e^{-\int p(x)dx}\left(  \int e^{\int p(x)dx}f(x)dx + C \right)
\end{align}\]</span></p>
<blockquote>
<p>Of course, to get a closed form formula for <span
class="math inline">\(y\)</span>, we need to be able to find a closed
form formula for the integrals appearing above</p>
</blockquote>
<h2 id="nonlinear-autonomous-systems-of-odes">Nonlinear Autonomous
Systems of ODEs</h2>
<p>We restrict our attention to a two-dimensional autonomous system
<span class="math display">\[\begin{align}
x&#39; &amp;= f(x,y) \\
y&#39; &amp;= g(x,y)
\end{align}\]</span></p>
<p>where <span class="math inline">\(f(x,y)\)</span> and <span
class="math inline">\(g(x,y)\)</span> are functions of two variables,
and the derivatives are taken with respect to time <span
class="math inline">\(t\)</span></p>
<h2 id="critical-points">critical points</h2>
<p><strong>critical points</strong> are the points where both <span
class="math inline">\(f(x; y) = 0\)</span> and <span
class="math inline">\(g(x; y) = 0\)</span></p>
<h2 id="linearization">Linearization</h2>
<p>we want to linearize the two functions <span
class="math inline">\(f(x; y)\)</span> and <span
class="math inline">\(g(x; y)\)</span> that define this system. To do
so, we will replace <span class="math inline">\(f\)</span> and <span
class="math inline">\(g\)</span> by the <em>tangent plane</em>
approximation to the functions.</p>
<p>Since <span class="math inline">\((x_0; y_0)\)</span> is a critical
point, we know that <span class="math inline">\(f(x_0; y_0) =
0\)</span>, so the tangent plane is given by <span
class="math display">\[
L_f(x; y) = f_x(x_0; y_0)(x − x_0) + f_y(x_0; y_0)(y − y_0)
\]</span> Similarly, the tangent plane for <span
class="math inline">\(g(x; y)\)</span> near the critical point <span
class="math inline">\((x_0; y_0)\)</span> is given by <span
class="math display">\[
L_g(x; y) = g_x(x_0; y_0)(x − x_0) + g_y(x_0; y_0)(y − y_0)
\]</span> That means that we can <em>approximate</em> the solution to
<span class="math inline">\(x&#39; = f(x,y);\quad y&#39; =
g(x,y)\)</span> near the critical point <span
class="math inline">\((x_0, y_0)\)</span> <em>by</em> the solution to
the system <span class="math display">\[\begin{align}
\frac{dx}{dt} &amp;= f_x(x_0, y_0)(x − x_0) + f_y(x_0, y_0)(y − y_0) \\
\frac{dy}{dt} &amp;= g_x(x_0, y_0)(x − x_0) + g_y(x_0, y_0)(y − y_0)
\end{align}\]</span></p>
<p>Next, change variables to <span class="math inline">\((u,v)\)</span>.
That is <span class="math inline">\(u=x-x_0; \quad v=y-y_0\)</span>, so
that <span class="math inline">\((u,v)=(0,0)\)</span> corresponds to
<span class="math inline">\((x_0, y_0)\)</span></p>
<blockquote>
<p>Notice changing variables is not going to affect our differential
equations because <span class="math inline">\(x_0\)</span> and <span
class="math inline">\(y_0\)</span> are constant. <span
class="math display">\[\begin{align}
\frac{dx}{dt} &amp;= \frac{du}{dt} \\
\frac{dy}{dt} &amp;= \frac{dv}{dt}
\end{align}\]</span></p>
</blockquote>
<p>The <em>linearization</em> as the linear system <span
class="math display">\[
\begin{bmatrix}
u \\
v
\end{bmatrix}&#39;
=
\begin{bmatrix}
\frac{\partial f}{\partial x}(x_0,y_0) &amp; \frac{\partial f}{\partial
y}(x_0,y_0) \\
\frac{\partial g}{\partial x}(x_0,y_0) &amp; \frac{\partial g}{\partial
y}(x_0,y_0)
\end{bmatrix}
\begin{bmatrix}
u \\
v
\end{bmatrix}
\]</span></p>
<blockquote>
<p><strong>Jacobian matrix</strong>: derivative matrix</p>
</blockquote>
<h2 id="conservative-equations">Conservative equations</h2>
<p>An equation of the form <span class="math display">\[
x&#39;&#39; + f(x)=0
\]</span> for an arbitrary function <span
class="math inline">\(f(x)\)</span> is called a <strong>conservative
equation</strong></p>
<blockquote>
<p>The equations are conservative as there is no friction in the system
so the energy in the system is "conserved".</p>
</blockquote>
<p>Let us write this equation as a system of nonlinear ODE <span
class="math display">\[
x&#39; = y, \quad y&#39; = -f(x)
\]</span></p>
<p>Assume that we have an <em>autonomous system</em> of differential
equations defining <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>, <span class="math display">\[
x&#39; = f(x,y), \quad y&#39; = g(x,y)
\]</span> A <strong>trajectory</strong> for this system is a curve in
the <span class="math inline">\(xy\)</span>-plane that the solution
curve <span class="math inline">\((x(t); y(t))\)</span> will <em>stay
on</em> for <strong>all</strong> <span
class="math inline">\(t\)</span>.</p>
<blockquote>
<p>This curve will generally be given with</p>
<ul>
<li><span class="math inline">\(y\)</span> as a function of <span
class="math inline">\(x\)</span>,</li>
<li>or the level curve of some function <span class="math inline">\(F(x;
y)\)</span>.</li>
</ul>
</blockquote>
<h2 id="hamiltonian-systems">Hamiltonian Systems</h2>
<p>A generalization of <em>conservative equations</em> to systems is a
<strong>Hamiltonian system</strong>.</p>
<p>For these systems, the point is that the equation has a <em>conserved
quantity</em> called a <strong>Hamiltonian</strong>, which <em>does not
change as the system evolves in time</em>, which generally represents
the <em>energy of the system</em>. Calling this function <span
class="math inline">\(H(x; y)\)</span>, this means that <span
class="math display">\[
\frac{d}{dt}H(x,y) = 0
\]</span> Below give the definition of <strong>Hamiltonian
system</strong>:</p>
<blockquote>
<p>The system <span class="math display">\[\begin{align}
\frac{dx}{dt} &amp;= f(x,y) \\
\frac{dy}{dt} &amp;= g(x, y)
\end{align}\]</span></p>
<p>is <strong>Hamiltonian</strong> if there is a function <span
class="math inline">\(H(x,y)\)</span> so that <span
class="math display">\[\begin{align}
f(x,y) &amp;=-\frac{\partial H}{\partial y} \\
g(x,y) &amp;= \frac{\partial H}{\partial x}
\end{align}\]</span></p>
</blockquote>
<h2 id="limit-cycles">Limit cycles</h2>
<p>unforced nonlinear time-invariant differential systems of the form
<span class="math display">\[
\frac{d\mathbf{x}}{dt}=\mathbf{f(x)}
\]</span></p>
<p>For nonlinear systems, trajectories do not simply need to approach or
leave a single point. They may in fact approach a larger set, such as a
<em>circle</em> or <em>another closed curve</em>.</p>
<h2 id="poincarébendixson-theorem">Poincaré–Bendixson Theorem</h2>
<h2 id="mathieus-equation">Mathieu's equation</h2>
<h2 id="floquet-theory">Floquet Theory</h2>
<blockquote>
<p>The general theory of linear differential equations with periodic
coefficients</p>
</blockquote>
<p>When a small perturbation <span
class="math inline">\(\mathbf{\delta}(t)\)</span> is applied to a
periodic orbit <span class="math inline">\(\mathbf{x}_c(t)\)</span> so
that the oscillator position is <span class="math display">\[
\mathbf{x}(t)=\mathbf{x}_c(t)+\mathbf{\delta}(t)
\]</span> by performing a Taylor series expansion in the vicinity of
<span class="math inline">\(\mathbf{x}_c(t)\)</span>, we obtain</p>
<p><span class="math display">\[\begin{align}
\frac{d}{dt}(\mathbf{x}_c(t)+\mathbf{\delta}(t)) &amp;=
\mathbf{f}(\mathbf{x}_c(t)+\mathbf{\delta}(t)) \\
&amp;= \mathbf{f}(\mathbf{x}_c(t)) + \mathbf{A}(t)\mathbf{\delta}(t) +
O(||\mathbf{\delta}(t)||^2)
\end{align}\]</span></p>
<p>where <span class="math display">\[
\mathbf{A}(t) = \mathbf{J}(\mathbf{x}_c(t))
\]</span> denotes the vector field Jacobian evaluted along the periodic
orbit <span class="math inline">\(\mathbf{x}_c(t)\)</span></p>
<p>This indicates that small trajectory perturbations satisfy the linear
differential equation <span class="math display">\[
\frac{d\mathbf{\delta}}{dt} = \mathbf{A}(t)\mathbf{\delta}(t)
\]</span></p>
<blockquote>
<p>where <span class="math inline">\(\mathbf{A}(t)\)</span> is periodic
with period <span class="math inline">\(T\)</span> since <span
class="math inline">\(\mathbf{x}_c(t)\)</span> is periodic with the same
period</p>
</blockquote>
<p>Since <span class="math inline">\(\mathbf{x}_c(t)\)</span> solves the
differential equation, by differentiating <span class="math display">\[
\frac{d\mathbf{x}_c(t)}{dt} =\mathbf{f}(\mathbf{x}_c(t)
\]</span> we obtain <span class="math display">\[
\frac{d}{dt}\left(\frac{d\mathbf{x}_c(t)}{dt}\right)
=\frac{d\mathbf{f}}{d\mathbf{x}_c}\frac{d\mathbf{x}_c(t)}{dt}
\]</span> and denoting <span
class="math inline">\(\mathbf{v}(t)=d\mathbf{x}_c/dt\)</span>, then
<span class="math display">\[
\frac{d\mathbf{v}}{dt} = \mathbf{A}(t)\mathbf{v}(t)
\]</span> where the velocity vector <span
class="math inline">\(\mathbf{v}(t)\)</span> is periodic with period
<span class="math inline">\(T\)</span> and is tangent to orbit <span
class="math inline">\(C\)</span> at point <span
class="math inline">\(\mathbf{x}_c(t)\)</span></p>
<blockquote>
<p><strong>SPECIAL CASE:</strong></p>
<p>If the initial perturbation <span
class="math inline">\(\mathbf{\delta}(0)\)</span> is colinear with
vector <span class="math inline">\(\mathbf{v}(0)\)</span>, i.e., <span
class="math inline">\(\mathbf{\delta}(0) = \alpha
\mathbf{v}(0)\)</span>, then <span class="math display">\[
\mathbf{\delta}(t) = \alpha \mathbf{v}(t)
\]</span> for all <span class="math inline">\(t\)</span>, so that in
this case <span class="math inline">\(\mathbf{\delta}(t)\)</span>
<strong>remain</strong> colinear with <span
class="math inline">\(\mathbf{v}(t)\)</span> and is periodic with period
<span class="math inline">\(T\)</span></p>
</blockquote>
<p>Since the oscillator orbit we consider is stable, small perturbations
in <strong>directions other than the tangent to the trajectory</strong>
must <strong>disappear</strong> as <span
class="math inline">\(t\)</span> becomes large.</p>
<p>i.e., if <span class="math inline">\(\mathbf{\delta}(0)\)</span> has
no component along the <span
class="math inline">\(\mathbf{v}(0)\)</span> direction, we must have
<span class="math display">\[
\lim_{t\to \infty}\mathbf{\delta}(t) = 0
\]</span></p>
<h2 id="chaos">Chaos</h2>
<p>Achaotic system is extremely sensitive to initial conditions.</p>
<p>A small change in the initial conditions yields a very different
solution after a reasonably short time</p>
<h2 id="riemann-integral">Riemann integral</h2>
<p><em>standard</em> (Riemann) integral <span class="math display">\[
\int_0^T f(t)dt = \lim_{N\to\infty}\sum_{k=0}^{N-1}f(\tilde{t_k})\Delta
t_k,\quad\Delta t_k=t_{k+1}-t_k
\]</span> where the width of each interval is <span
class="math inline">\(T/N\)</span>, and for each interval <span
class="math inline">\(\Delta t_k\)</span>, we choose a value <span
class="math inline">\(\tilde{t_k}\in[t_k,t_{k+1}]\)</span> at which we
evaluate the function.</p>
<p><img src="/2023/10/05/nonlinearSystem/riemann_int.png"
alt="The Riemann integral construction; divide the function up into rectangles. Here, I’ve evaluated the function at the left edge of each rectangle." /></p>
<p>The Riemann integral construction; divide the function up into
rectangles. Here, I’ve evaluated the function at the <em>left edge</em>
of each rectangle.</p>
<blockquote>
<p>For <em>ordinary, smooth functions</em>, of course, this integral
converges to the same value <em>no matter</em> where we choose our
rectangle heights <span class="math inline">\(\tilde{t_k}\)</span> in
the interval.</p>
<p>However, Brownian motion is <em>less well behaved</em>.</p>
</blockquote>
<h2 id="lebesgue-integral">Lebesgue integral</h2>
<p>[<a target="_blank" rel="noopener" href="https://qr.ae/py5x6K">What is the difference between a
Riemann and a Lebesgue integral, and why is the latter needed?</a>]</p>
<p>Riemann integration:</p>
<p><img src="/2023/10/05/nonlinearSystem/image-20230702004840807.png"
alt="image-20230702004840807" /></p>
<blockquote>
<p>The disadvantage of the Riemann integral is that it privileges the
role of intervals. It is ineffective when applied to a highly
discontinuous function</p>
</blockquote>
<p>Lebesgue integration:</p>
<p><img src="/2023/10/05/nonlinearSystem/image-20230702005049938.png"
alt="image-20230702005049938" /></p>
<h2 id="measure-and-probabilities">Measure and Probabilities</h2>
<blockquote>
<p>Probality is a measure of the size of a set</p>
</blockquote>
<h2 id="power-set">power set</h2>
<h2 id="sigma-algebra"><span
class="math inline">\(\sigma\)</span>-Algebra</h2>
<p>or <span class="math inline">\(\sigma\)</span>-field, Sigma-field</p>
<h2 id="measurable-space">measurable space</h2>
<p>If <span class="math inline">\(X\)</span> is a set and <span
class="math inline">\(A\)</span> is a <span
class="math inline">\(\sigma\)</span>-algebra on <span
class="math inline">\(X\)</span>, then the tuple <span
class="math inline">\((X,A)\)</span> is called the <strong>measurable
space</strong> (also <strong>Borel space</strong>)</p>
<h2 id="probability-space">probability space</h2>
<h2 id="filtration-and-information-flow">filtration and information
flow</h2>
<h2 id="martingale">martingale</h2>
<p>A stochastic process <span class="math inline">\(M_t\)</span> is a
<strong>martingale</strong> if</p>
<ul>
<li><p>its <em>mean</em> is bounded</p></li>
<li><p>and <em>the conditional expectation given access to it’s history
up to time</em> <span class="math inline">\(t&#39;\)</span> is equal to
the value at that time</p></li>
</ul>
<p>that is <span class="math display">\[\begin{align}
\mathbb{E}[|M_t|] &amp;\lt \infty \\
\mathbb{E}[M_t|{M_s,s\leq t&#39;}] &amp;= M_{t&#39;}, \quad \text{for
all } t&#39;\leq t
\end{align}\]</span></p>
<blockquote>
<p>In less formal language, this means that the “best guess" for the
future value of a martingale is always the most recent observed value;
knowing <span class="math inline">\(M_{t&#39;}\)</span> is just as good
as knowing the entire history of <span
class="math inline">\(M_t\)</span> up to <span
class="math inline">\(t&#39;\)</span></p>
<p>If <span class="math inline">\(W_t\)</span> is your wealth at the
<span class="math inline">\(t^{th}\)</span> round of a fair game, like
betting on a coin flip, then <span class="math inline">\(W_t\)</span> is
a martingale; on average you end up with the same amount of money you
started with.</p>
</blockquote>
<h2 id="wss-process">WSS process</h2>
<p>A random process <span class="math inline">\(X(t)\)</span> is
<strong>wide-sense stationary</strong> if:</p>
<ol type="1">
<li><span class="math inline">\(\mu _x(t)=\text{constant}\)</span>, for
all <span class="math inline">\(t\)</span>, and</li>
<li><span class="math inline">\(R_X(t_1, t_2)=R_x(t_1-t_2)\)</span> for
all <span class="math inline">\(t_1, t_2\)</span></li>
</ol>
<h2 id="autocorrelation">autocorrelation</h2>
<p><span class="math display">\[
R_X(t_1, t_2) = \mathbb{E}[X(t_1)X(t_2)]
\]</span></p>
<h2 id="temporal-average">temporal average</h2>
<p>Consider the following function: <span class="math display">\[
\hat{R_X}(\tau) = \frac{1}{2T}\int_{-T}^{T}X(t+\tau)X(t)dt
\]</span> This function is the temporal average of <span
class="math inline">\(X(t+\tau)X(t)\)</span></p>
<p>Then <span class="math display">\[
\mathbb{E}[\hat{R_X}(\tau)] = R_X(\tau)
\]</span></p>
<h2 id="power-spectral-density">power spectral density</h2>
<h3 id="time-domain">time domain</h3>
<p>Define <span class="math display">\[
P_X = \mathbb{E}\left[ \lim_{T\to
\infty}\frac{1}{2T}\int_{-T}^{T}|X(t)|^2dt \right]
\]</span> Then we have <span class="math inline">\(P_X =
\frac{1}{2\pi}\int_{-\infty}^{\infty}S_X(\omega)d\omega\)</span> or
<span class="math inline">\(P_X =
\int_{-\infty}^{\infty}S_X(f)df\)</span></p>
<h2 id="frequency-domain">frequency domain</h2>
<p>The <em>power spectral density (PSD)</em> of a <em>WSS process</em>
is defined as <span class="math display">\[
S_X(\omega) = \lim_{T\to
\infty}\frac{\mathbb{E}[|\tilde{X}_T(\omega)|^2]}{2T}
\]</span> where <span class="math inline">\(\tilde{X}_T(\omega) =
\int_{-T}^{T}X(t)e^{-j\omega t}dt\)</span> is the Fourier transform of
<span class="math inline">\(X(t)\)</span> limited to <span
class="math inline">\([-T, T]\)</span>, Parseval's theorem is
applied.</p>
<p>That is <span class="math display">\[\begin{align}
P_X  &amp;= \frac{1}{2\pi}\int_{-\infty}^{\infty}S_X(\omega)d\omega \\
&amp;= \frac{1}{2\pi}\int_{-\infty}^{\infty}\lim_{T\to
\infty}\frac{\mathbb{E}[|\tilde{X}_T(\omega)|^2]}{2T}d\omega
\end{align}\]</span></p>
<h2 id="einstein-wiener-khinchin-theorem">Einstein-Wiener-Khinchin
Theorem</h2>
<blockquote>
<p>The Einstein-Wiener-Khinchin theorem is a fundamental result. It
states that for any <em>wide sense stationary process</em>, the power
spectral density <span class="math inline">\(S_X(\omega)\)</span> is the
Fourier transform of the autocorrelation function.</p>
</blockquote>
<p>The power spectral density <span
class="math inline">\(S_X(\omega)\)</span> of a <em>WSS process</em> is
<span class="math display">\[
S_X(\omega) = \int_{-\infty}^{\infty}R_X(\tau)e^{-j\omega \tau}d\tau =
\mathcal{F}(R_X(\tau))
\]</span> assuming that <span
class="math inline">\(\int_{-\infty}^{\infty}R_X(\tau)^2d\tau \lt
\infty\)</span> so that the Fourier transform of <span
class="math inline">\(R_X(\tau)\)</span> exists</p>
<p><img src="/2023/10/05/nonlinearSystem/image-20230715101317632.png"
alt="image-20230715101317632" /></p>
<h2 id="wiener-process-or-brownian-motion">Wiener Process (or Brownian
Motion)</h2>
<blockquote>
<p><span class="math inline">\(\text{SDE} = \text{ODE} +
\text{GWN}\)</span></p>
<p>where <span class="math inline">\(\text{GWN}\)</span> is
<strong>Gaussian White Noise</strong></p>
</blockquote>
<p>a Brownian Motion <span
class="math inline">\(\{W_t\}_{t:t\in[0,\infty]}\)</span> is a
stochastic process, whose conditional likelihood is Gaussian with a
variance that increase linearly in the time interval that one considers
and a zero mean</p>
<ul>
<li><span class="math inline">\(W_0 = 0\)</span></li>
<li><span class="math inline">\(W_t \sim \mathbb{N}(0, t)\)</span></li>
<li><span class="math inline">\(W_{t2} - W_{t1}\)</span> is independent
from <span class="math inline">\(W_{t4} - W_{t3}\)</span> for <span
class="math inline">\(0\leq t_1\leq t_2 \leq t_3 \leq t_4\)</span></li>
</ul>
<blockquote>
<p>Brownian motion <span class="math inline">\(W_t\)</span> is an
example of a <strong>Gaussian process</strong></p>
<p>Wiener process can be thought of as the <strong>integral</strong> of
white noise</p>
</blockquote>
<p>The implications of these assumptions are: <span
class="math display">\[
E[W_t] = 0
\]</span></p>
<p><span class="math display">\[
Var(W_t) = E[W_t^2] = t
\]</span></p>
<ul>
<li><p>A single trajectory <span class="math inline">\(t \to
W_t(\omega)\)</span> is <strong>continuous</strong>, yet extremely
spiky, that is <span class="math inline">\(\frac{dW_t}{dt}\)</span>
<strong>does not</strong> exist.</p></li>
<li><p>Yet, the Brownian Motion itself is well defined of course. that
is <span class="math inline">\(W_t = \int_0^tdW_u\)</span>
<strong>does</strong> exist</p></li>
</ul>
<p><span class="math display">\[
W_t = \int_0^tdW_u
\]</span></p>
<p>What does it really mean?</p>
<ul>
<li><span class="math inline">\(dW_t \sim \mathbb{N}(0,
dt)\)</span></li>
<li><span class="math inline">\(\frac{dW_t}{dt}\sim
\mathbb{N}(0,1)\)</span></li>
</ul>
<p><img src="/2023/10/05/nonlinearSystem/image-20230702094054155.png"
alt="image-20230702094054155" /></p>
<h2 id="ito-sde-with-brownian-motion">Ito SDE with Brownian Motion</h2>
<p><span class="math display">\[
\frac{dX_t}{dt} = f(X_t) + g(X_t)\frac{dW_t}{dt}
\]</span></p>
<p>is not well defined and hence only a popular <em>'Symbolic
Representation'</em></p>
<p>For SDEs, the proper representation is the <strong>'Pathwise
Stochastic Integral Representation'</strong></p>
<p><img src="/2023/10/05/nonlinearSystem/image-20230702155217093.png"
alt="image-20230702155217093" /></p>
<blockquote>
<p><strong>stochastic integral</strong>:</p>
<p>It doesn’t have the same geometrically intuitive nature as the
Riemann integral, but there is an analogy here;</p>
<p>instead of a finite sum of simple functions which are rectangles, we
are now dealing with <strong>a finite sum of 'simple random variables'
multiplied by increments of a Brownian walk</strong>, which are
Gaussian.</p>
</blockquote>
<h2 id="stochastic-differential-equation-sde">stochastic differential
equation (SDE)</h2>
<h2 id="wiener-stochastic-integral">Wiener Stochastic Integral</h2>
<p>Let <span class="math inline">\(L^2([0,T])\)</span> denote the space
of measurable functions <span
class="math inline">\(f:[0,T]\longrightarrow \mathbb{R}\)</span> such
that <span class="math display">\[
||f||_{L^2([0,T])}=\sqrt{\int_0^T|f(t|^2dt}\lt \infty
\]</span> In the above definition, <span
class="math inline">\(||f||_{L^2([0,T])}\)</span> represents the norm of
the function <span class="math inline">\(f\in L^2([0,T])\)</span>, and
known as <em>square-integrable functions</em></p>
<p><span class="math inline">\(\int_0^Tf(t)dB_t\)</span> has the
centered Gaussian distribution <span class="math display">\[
\int_0^Tf(t)dB_t \simeq \mathbb{N}\left(0,\int_0^T|f(t)|^2dt\right)
\]</span> where <span class="math inline">\(f\in L^2([0,T])\)</span></p>
<p>The Wiener stochastic integral <span class="math inline">\(\int_0^T
f(t)dB_t\)</span> is a Gaussian random variable that cannot be
"computed" in the way standard integrals are computed via the use of
primitives. However, when <span class="math inline">\(f\in
L^2([0,T])\)</span> and is continuously differentiable on <span
class="math inline">\([0,T]\)</span>, we have the integration by parts
relation <span class="math display">\[
\int_0^Tf(t)dB_t = f(T)B_T -\int_0^TB_tf&#39;(t)dt
\]</span></p>
<h2 id="ito-stochastic-integral">Ito Stochastic Integral</h2>
<p>The biggest advantage of Ito formulation is that the evaluations of
the function are totally uncorrelated with the increment, by
contruction.</p>
<p>That is to say, that because we evaluate the function <span
class="math inline">\(f(x,B_t, t)\)</span> at the <strong>left</strong>
point of the midpoint, our limiting sum is <span class="math display">\[
\int f(x,B_t, t)dB_t = \lim_{N\to \infty}\sum
f(x_{t_k},B_{t_k},t_k)(B_{t_{k+1}}-B_{t_k})
\]</span></p>
<blockquote>
<p>For a deterministic integral, the convergence of the integral does
<strong>NOT</strong> depend on wheter the integrands is evaluated at the
left, mid or end point.</p>
<p>The Ito stochastic integral uses the left end point for the
integrand.</p>
</blockquote>
<p>But because the increment <span
class="math inline">\((B_{t_{k+1}}-B_{t_k})\)</span> is
<strong>uncorrelated</strong> with <span
class="math inline">\(B_{t_k}\)</span>, it's also <strong>uncorrelated
with any function of <span
class="math inline">\(B_{t_k}\)</span></strong>, i.e. <span
class="math inline">\(f(x_{t_k},B_{t_k},t_k)\)</span>. and the limiting
sum always has <strong>mean zero </strong></p>
<p>This leads to the nice property that an Ito integral <span
class="math display">\[
\int _S ^ T f(x, t)dB_t
\]</span> always has mean zero, and is a martingale</p>
<blockquote>
<p><span class="math inline">\(f(x, t)\)</span> omit <span
class="math inline">\(B_t\)</span> due to uncorrelated property</p>
</blockquote>
<h2 id="quadratic-variation">quadratic variation</h2>
<p>Step function approximation of Brownian motion</p>
<p><span class="math display">\[\begin{align}
E\left[\left( \int_0^Tu_t dB_t \right)^2\right] &amp;= E\left[\int_0^T
|u_t|^2 dt \right] \\
E\left[\int_0^T u_t dB_t\right] &amp;= 0
\end{align}\]</span></p>
<h2 id="basic-ito-formula">Basic Ito formula</h2>
<p>For <span class="math inline">\(f\)</span> is twice continuously
differentiable on <span class="math inline">\([0, T]\)</span>, Taylor's
formula written at the second order for Brownian motion reads <span
class="math display">\[
df(B_t) = f&#39;(B_t)dB_t + \frac{1}{2}f^{&#39;&#39;}(B_t)dt
\]</span> for <strong>infinitesimally small</strong> <span
class="math inline">\(dt\)</span>.</p>
<p>Note that writing this formula as <span class="math display">\[
\frac{df(B_t)}{dt}=f&#39;(B_t)\frac{dB_t}{dt}+\frac{1}{2}f^{&#39;&#39;}(B_t)
\]</span> <strong>does not</strong> make sense because the pathwise
derivative <span class="math display">\[
\frac{dB_t}{dt}\simeq \pm\frac{\sqrt{dt}}{dt}\simeq
\pm\frac{1}{\sqrt{dt}}\simeq \pm\infty
\]</span> of <span class="math inline">\(B_t\)</span> with respect to
<span class="math inline">\(t\)</span> does not exist.</p>
<p>With <span class="math inline">\(f(B_t)-f(B_0)=\int_0^t
df(B_s)\)</span>, we get the integral form of Ito formula for Brownian
motion <span class="math display">\[
f(B_t) =
f(B_0)+\int_0^tf&#39;(B_s)dB_s+\frac{1}{2}\int_0^tf^{&#39;&#39;}(B_s)ds
\]</span></p>
<h2 id="ito-processes">Ito processes</h2>
<p>A stochastic process <span class="math inline">\((X_t)_{t\in
\mathbb{R}_+}\)</span> that can be written as <span
class="math display">\[
X_t = X_0 + \int_0^t v_sds + \int_0^t u_sdB_s,\quad t\geq0
\]</span> or differential notation <span class="math display">\[
dX_t = v_tdt + u_tdB_t
\]</span> where <span
class="math inline">\((u_t)_{t\in\mathbb{R}_+}\)</span> and <span
class="math inline">\((v_t)_{t\in\mathbb{R}_+}\)</span> are
<em>square-integrable adapted process</em></p>
<h2 id="ito-formula-for-ito-processes">Ito formula for Ito
processes</h2>
<p>For any Ito process <span
class="math inline">\((X_t)_{t\in\mathbb{R}_+}\)</span> and any <span
class="math inline">\(f\)</span> that is continuously differentiable on
<span class="math inline">\(t\in[0,T]\)</span> and twice differentiable
in <span class="math inline">\(x\in\mathbb{R}\)</span>, with bounded
derivatives <span class="math display">\[
f(t,X_t) = f(0,X_0)+\int_0^t\frac{\partial f}{\partial s}(s,X_s)ds +
\int_0^t v_s\frac{\partial f}{\partial x}(s,X_s)ds + \int_0^t
u_s\frac{\partial f}{\partial
x}(s,X_s)dB_s+\frac{1}{2}\int_0^t|u_s|^2\frac{\partial ^2 f}{\partial
x^2}(s,X_s)ds
\]</span> Due to <span class="math inline">\(\int_0^t
df(s,X_s)=f(t,X_t)-f(0,X_0)\)</span> <span class="math display">\[
\int_0^t df(s,X_s)=\int_0^t\frac{\partial f}{\partial s}(s,X_s)ds +
\int_0^t v_s\frac{\partial f}{\partial x}(s,X_s)ds + \int_0^t
u_s\frac{\partial f}{\partial
x}(s,X_s)dB_s+\frac{1}{2}\int_0^t|u_s|^2\frac{\partial ^2 f}{\partial
x^2}(s,X_s)ds
\]</span> which allow us to rewrite in differential notation, as <span
class="math display">\[
df(t,X_t) = \frac{\partial f}{\partial t}(t,X_t)dt + v_t\frac{\partial
f}{\partial x}(t, X_t)dt+u_t\frac{\partial f}{\partial
x}(t,X_t)dB_t+\frac{1}{2}|u_t|^2\frac{\partial ^2 f}{\partial x^2}(t,
X_t)dt
\]</span></p>
<ul>
<li><p>In case the function <span class="math inline">\(x \to
f(x)\)</span> does <strong>not depend on the time variable <span
class="math inline">\(t\)</span></strong>, we get <span
class="math display">\[
df(X_t) = v_t\frac{\partial f}{\partial x}(X_t)dt+u_t\frac{\partial
f}{\partial x}(X_t)dB_t+\frac{1}{2}|u_t|^2\frac{\partial ^2 f}{\partial
x^2}(X_t)dt
\]</span></p></li>
<li><p><span class="math inline">\(X_t = B_t\)</span> while taking <span
class="math inline">\(v_t=0\)</span>, <span
class="math inline">\(u_t=1\)</span> and <span
class="math inline">\(X_0=0\)</span> in Ito process, Ito formula reads
<span class="math display">\[
f(t, B_t) = f(0, B_0)+\int_0^t\frac{\partial f}{\partial s}(s,B_s)ds +
\int_0^t\frac{\partial f}{\partial
x}(s,B_s)dB_s+\frac{1}{2}\int_0^t\frac{\partial ^2 f}{\partial
x^2}(s,B_s)ds
\]</span> i.e. in differential notation: <span class="math display">\[
df(t, B_t) = \frac{\partial f}{\partial t}(t,B_t)dt + \frac{\partial
f}{\partial x}(t,B_t)dB_t+\frac{1}{2}\frac{\partial ^2 f}{\partial
x^2}(t,B_t)dt
\]</span></p></li>
</ul>
<hr />
<p><strong>Ito Lemma</strong>, it says that if the input to a function
follows an Ito SDE, then the output to a sufficiently smooth function
follows also an Ito SDE.</p>
<p><img src="/2023/10/05/nonlinearSystem/image-20230702160220762.png"
alt="image-20230702160220762" /></p>
<hr />
<h2 id="bivariate-ito-formula">Bivariate Ito formula</h2>
<p>Consider two Ito processes <span class="math inline">\((X_t)_{t\in
\mathbb{R} _+}\)</span> and <span class="math inline">\((Y_t)_{t\in
\mathbb{R} _+}\)</span> written in <em>integral form</em> as</p>
<p><span class="math display">\[\begin{align}
X_t &amp;= X_0 + \int_0^t v_sds + \int_0^t u_s dB_s, \quad t \geq 0 \\
Y_t &amp;= Y_0 + \int_0^t b_sds + \int_0^t a_s dB_s, \quad t \geq 0
\end{align}\]</span></p>
<p>or in <em>differential notation</em> as</p>
<p><span class="math display">\[\begin{align}
dX_t &amp;= v_t dt +u_tdB_t \\
dY_t &amp;= b_tdt + a_tdB_t
\end{align}\]</span></p>
<p>The Ito formula can also be written for functions <span
class="math inline">\(f\)</span> of two state variables as</p>
<p><span class="math display">\[\begin{align}
df(t,X_t, Y_t) &amp;= \frac{\partial f}{\partial t}(t,X_t,Y_t)dt +
\frac{\partial f}{\partial x}(t, X_t, Y_t)dX_t +
\frac{1}{2}|u_t|^2\frac{\partial ^2 f}{\partial x^2}(t, X_t, Y_t)dt \\
&amp;+\frac{\partial f}{\partial y}(t, X_t, Y_t)d_t +
\frac{1}{2}|a_t|^2\frac{\partial ^2 f}{\partial y^2}(t, X_t, Y_t)dt +
u_ta_t\frac{\partial ^2 f}{\partial x \partial y}(t,X_t,Y_t)dt
\end{align}\]</span></p>
<h2 id="ito-multiplication-table">Ito multiplication table</h2>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(\cdot\)</span></th>
<th><span class="math inline">\(dt\)</span></th>
<th><span class="math inline">\(dB_t\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(dt\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(dB_t\)</span></td>
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(dt\)</span></td>
</tr>
</tbody>
</table>
<p>That is</p>
<p><span class="math display">\[\begin{align}
dt\cdot dt &amp;= 0 \\
dt\cdot dB_t &amp;= 0 \\
dB_t \cdot dB_t &amp;= dt
\end{align}\]</span></p>
<p>It follows from above Ito table that</p>
<p><span class="math display">\[\begin{align}
dX_t \cdot dY_t &amp;= (v_tdt+u_tdB_t)\cdot (b_tdt + a_tdB_t) \\
&amp;= b_tv_t(dt)^2+b_tu_tdtdB_t +a_tv_tdtdB_t +a_tu_t(dB_t)^2 \\
&amp;= a_tu_t dt
\end{align}\]</span></p>
<p>and we also have <span class="math display">\[\begin{align}
(dX_t)^2 &amp;= (v_tdt + u_tdB_t)^2 \\
&amp;= (v_t)^2 (dt)^2 + (u_t)^2(dB_t)^2 + 2u_tv_t(dt\cdot dB_t) \\
&amp;= (u_t)^2dt
\end{align}\]</span></p>
<blockquote>
<p><span class="math inline">\(dB_t = \sqrt{dt}\)</span></p>
</blockquote>
<h2 id="ito-formula-using-ito-multiplication-table">Ito formula using
Ito multiplication table</h2>
<p>with <span class="math inline">\((u_t)^2dt=(dX_t)^2\)</span> and
<span class="math inline">\(X_t = v_tdt + u_tdB_t\)</span>, Ito
formula's differential notation can be rewritten as <span
class="math display">\[\begin{align}
df(t,X_t) &amp;= \frac{\partial f}{\partial t}(t,X_t)dt +
v_t\frac{\partial f}{\partial x}(t, X_t)dt+u_t\frac{\partial f}{\partial
x}(t,X_t)dB_t+\frac{1}{2}|u_t|^2\frac{\partial ^2 f}{\partial x^2}(t,
X_t)dt \\
&amp;= \frac{\partial f}{\partial t}(t,X_t)dt + \frac{\partial
f}{\partial x}(t,X_t)\cdot (v_tdt + u_tdB_t) + \frac{1}{2}\frac{\partial
^2 f}{\partial x^2}(t, X_t)\cdot |u_t|^2dt \\
&amp;= \frac{\partial f}{\partial t}(t,X_t)dt + \frac{\partial
f}{\partial x}(t,X_t)dX_t + \frac{1}{2}\frac{\partial ^2 f}{\partial
x^2}(t, X_t)\cdot (dX_t)^2 \\
&amp; = \frac{\partial f}{\partial t}(t,X_t)dt + \frac{\partial
f}{\partial x}(t,X_t)dX_t + \frac{1}{2}\frac{\partial ^2 f}{\partial
x^2}(t, X_t)dX_t\cdot dX_t
\end{align}\]</span></p>
<p>and the Ito formula for function <span
class="math inline">\(f\)</span> of two state variables can be rewritten
as</p>
<p><span class="math display">\[\begin{align}
df(t,X_t, Y_t)
&amp;= \frac{\partial f}{\partial t}(t,X_t,Y_t)dt + \frac{\partial
f}{\partial x}(t, X_t, Y_t)dX_t + \frac{1}{2}\frac{\partial ^2
f}{\partial x^2}(t, X_t, Y_t)(dX_t))^2 \\
&amp;+\frac{\partial f}{\partial y}(t, X_t, Y_t)d_t +
\frac{1}{2}\frac{\partial ^2 f}{\partial y^2}(t, X_t, Y_t)(dY_t)^2 +
\frac{\partial ^2 f}{\partial x \partial y}(t,X_t,Y_t)(dX_t\cdot dY_t)
\end{align}\]</span></p>
<p>where <span class="math inline">\((dX_t)^2 = |u_t|^2dt\)</span>,
<span class="math inline">\((dY_t)^2=|a_t|^2dt\)</span> and <span
class="math inline">\(dX_t\cdot dY_t = u_ta_tdt\)</span></p>
<h2 id="solving-a-geometric-brownian-motion">Solving a Geometric
Brownian Motion</h2>
<h2 id="geometric-brownian-motion-gbm">Geometric Brownian motion
(GBM)</h2>
<p>A <strong>geometric Brownian motion (GBM)</strong> (also known as
<strong>exponential Brownian motion</strong>)</p>
<p>A stochastic process <span class="math inline">\(S_t\)</span> is said
to follow a <strong>GBM</strong> if it satisfies the following (SDE) [<a
target="_blank" rel="noopener" href="https://en.wikipedia.org/w/index.php?title=Geometric_Brownian_motion&amp;oldid=1161374200">link</a>]:
<span class="math display">\[
dS_t = \mu S_t dt + \sigma S_t dW_t
\]</span> where <span class="math inline">\(W_t\)</span> is a Wiener
process or Brownian motion</p>
<p>and <span class="math inline">\(\mu\)</span> ('the percentage drift')
and <span class="math inline">\(\sigma\)</span> ('the percentage
volatility') are constants.</p>
<blockquote>
<p>The former parameter is used to model deterministic trends,</p>
<p>while the latter parameter models unpredictable events occurring
during the motion.</p>
</blockquote>
<h2 id="solving-step-by-step">solving step by step</h2>
<p>[<a target="_blank" rel="noopener" href="https://youtu.be/y0s2GXREymI">Quant Guild</a>]</p>
<p>Given the stochastic differential equation <span
class="math display">\[
dS_t = \mu S_t dt + \sigma S_t dW_t, \quad t\in[t_0, T]
\]</span> that represents the dynamics of a stock process, it is
desirable to recover the function for simulation.</p>
<p>First, recall <strong>Ito lemma</strong> where <span
class="math inline">\(y(t, X_t)\)</span> represents a time-dependent
function of a stochastic process <span class="math display">\[
dy(t,X_t) = \frac{\partial y}{\partial t}dt + \frac{\partial y}{\partial
X_t}dX_t + \frac{1}{2}\frac{\partial ^2 y}{\partial X_t^2}(dX_t)^2
\]</span> Now, consider the following log transformation of the stock
process <span class="math display">\[
g(S_t) = \ln(S_t)
\]</span> We can apply Ito lemma to the log transformation function
<span class="math display">\[
dg(S_t) = \frac{\partial g}{\partial t}dt + \frac{\partial g}{\partial
S_t}dS_t +\frac{1}{2}\frac{\partial ^2 g}{\partial X_t^2}(dX_t)^2
\]</span> It follows from <span class="math inline">\(g(S_t) =
\ln(S_t)\)</span> and <span class="math inline">\(dS_t = \mu S_t dt +
\sigma S_t dW_t\)</span> with <em>Ito multiplication table</em> <span
class="math display">\[\begin{align}
\frac{\partial g}{\partial t} &amp;= 0 \\
\frac{\partial g}{\partial S_t} &amp;= \frac{1}{S_t} \\
\frac{\partial ^2  g}{\partial S_t ^2} &amp;= -\frac{1}{S_t^2} \\
(dX_t)^2 &amp;= 0 + 0 + \sigma^2S_t^2(dW_t)^2 = \sigma^2S_t^2dt
\end{align}\]</span></p>
<p>By substitution of these results into <span
class="math inline">\(dg(S_t) = \frac{\partial g}{\partial t}dt +
\frac{\partial g}{\partial S_t}dS_t +\frac{1}{2}\frac{\partial ^2
y}{\partial X_t^2}(dX_t)^2\)</span>, we obtain <span
class="math display">\[\begin{align}
dg(S_t) &amp;= 0 + \frac{1}{S_t}(\mu S_t dt + \sigma S_t dW_t) +
\frac{1}{2}(-\frac{1}{S_t^2})\sigma^2S_t^2dt \\
&amp;= \mu dt + \sigma dW_t - \frac{1}{2}\sigma^2 dt \\
&amp;= \left(\mu - \frac{1}{2}\sigma^2\right) + \sigma dW_t
\end{align}\]</span></p>
<p>We can now integrate both sides <span class="math display">\[
\int_{t_0}^Tdg(S_t) = \int_{t_0}^T \left(\mu -
\frac{1}{2}\sigma^2\right)dt + \int_{t_0}^T\sigma dW_t
\]</span></p>
<p><span class="math display">\[
g(S_t) - g(S_{t_0}) = \left(\mu - \frac{1}{2}\sigma^2\right)(T - {t_0})
+ \sigma(W_T - W_{t_0})
\]</span></p>
<p>Let's substitute <span class="math inline">\(g(S_t) =
\ln(S_t)\)</span> into above equation <span class="math display">\[
\ln(S_t) - \ln(S_{t_0}) = \left(\mu - \frac{1}{2}\sigma^2\right)(T -
{t_0}) + \sigma(W_T - W_{t_0})
\]</span> after arranging, the closed form solution is <span
class="math display">\[
S_T = S_{t_0}e^{(\mu-\frac{1}{2}\sigma^2)(T-t_0)+\sigma(W_T-W_{t_0})}
\]</span></p>
<h2 id="paper">paper</h2>
<p>A. Demir, A. Mehrotra and J. Roychowdhury, "Phase noise in
oscillators: a unifying theory and numerical methods for
characterization," in IEEE Transactions on Circuits and Systems I:
Fundamental Theory and Applications, vol. 47, no. 5, pp. 655-674, May
2000, doi: 10.1109/81.847872. [<a
target="_blank" rel="noopener" href="https://www.researchgate.net/profile/Jaijeet-Roychowdhury/publication/3774912_Phase_noise_in_oscillators_a_unifying_theory_and_numerical_methods_for_characterisation/links/56436c0308ae54697fb2e543/Phase-noise-in-oscillators-a-unifying-theory-and-numerical-methods-for-characterisation.pdf">pdf</a>]</p>
<p>demir, Alper. (2000). Floquet theory and non-linear perturbation
analysis for oscillators with differential-algebraic equations.
International Journal of Circuit Theory and Applications - INT J CIRCUIT
THEOR APPL. 28. 163-185.
10.1002/(SICI)1097-007X(200003/04)28:23.0.CO;2-K.</p>
<h2 id="book">book</h2>
<p>⭐ Levy, Bernard. (2020). <strong>Random Processes with Applications
to Circuits and Communications</strong>. 10.1007/978-3-030-22297-0.</p>
<p>Sundararajan, D.. (2023). <strong>Signals and Systems: A Practical
Approach</strong>. 10.1007/978-3-031-19377-4.</p>
<p>Øksendal, Bernt. (2000). <strong>Stochastic Differential Equations:
An Introduction with Applications</strong>.
10.1007/978-3-662-03185-8.</p>
<p>Chicone, Carmen Charles. <strong>Ordinary Differential Equations with
Applications. 2nd ed</strong>. New York ; Berlin: Springer, 2006.</p>
<p>⭐ Stanley H. Chan (2021). <strong>Introduction to Probability for
Data Science</strong>. Michigan Publishing, [<a
target="_blank" rel="noopener" href="https://probability4datascience.com/index.html">link</a>]</p>
<p>Simo Särkkä and Arno Solin (2019). <strong>Applied Stochastic
Differential Equations</strong>. Cambridge University Press. Cambridge,
UK. [<a target="_blank" rel="noopener" href="https://github.com/AaltoML/SDE">link</a>]</p>
<p>Gerald Teschl, <strong>Ordinary Differential Equations and Dynamical
Systems</strong> A.M.S., 2012</p>
<p>Kurt Bryan; Brian Winkel (2020), "2021-Bryan, Kurt - SIMIODE Online
Digital Textbook - <strong>Differential Equations: A Toolbox for
Modeling the World</strong>.,"
https://www.simiode.org/resources/8208.</p>
<p>Jordan, D.W. and Smith, P. (2007) <strong>Nonlinear Ordinary
Differential Equations: An Introduction for Scientists and Engineers.
4th Edition</strong>, Oxford University Press, New York.</p>
<p>Strogatz, S.H. (2015). <strong>Nonlinear Dynamics and Chaos: With
Applications to Physics, Biology, Chemistry, and Engineering (2nd
ed.)</strong>. CRC Press. https://doi.org/10.1201/9780429492563</p>
<p>⭐ Nicolas Privault. <strong>Introduction to Stochastic Finance with
Market Examples, Second Edition</strong>, Chapman &amp; Hall/CRC
Financial Mathematics Series, 2022</p>
<p>⭐ Nicolas Privault. <strong>MH4514 Financial Mathematics</strong>
[<a target="_blank" rel="noopener" href="https://personal.ntu.edu.sg/nprivault/indext.html">link</a>,
<a
target="_blank" rel="noopener" href="https://drive.google.com/file/d/1iCsMdtJctWK2fo65WP5iqNvQ73acObzU">MH4514_notes</a>]</p>
<p>Evans, Lawrence C.. <strong>Stochastic differential equations version
1.2</strong> [<a
target="_blank" rel="noopener" href="https://www.cmor-faculty.rice.edu/~cox/stoch/SDE.course.pdf">pdf</a>]</p>
<p>Evans, Lawrence C.. <strong>An Introduction to Stochastic
Differential Equations.</strong> (2014).</p>
<p>⭐ Matt Charnley. <strong>Differential Equations: An Introduction for
Engineers</strong> [<a
target="_blank" rel="noopener" href="https://sites.rutgers.edu/matthew-charnley/course-materials/differential-equations-an-introduction-for-engineers/">link</a>]</p>
<p>⭐ Jiří Lebl. <strong>Notes on Diffy Qs: Differential Equations for
Engineers</strong> [<a
target="_blank" rel="noopener" href="https://www.jirka.org/diffyqs/">link</a>]</p>
<h2 id="measure-theoretic-probability-theory">measure-theoretic
probability theory</h2>
<p>Jacod, J., &amp; Protter, P. (2004). <strong>Probability Essentials
(Second edition.)</strong>. Springer Berlin Heidelberg.</p>
<p>Sebastien Roch, UW-Madison. <strong>Lecture Notes on
Measure-theoretic Probability Theory</strong> [<a
target="_blank" rel="noopener" href="https://people.math.wisc.edu/~roch/grad-prob/index.html">link</a>]</p>
<p>Matthew N. Bernstein <strong>Demystifying measure-theoretic
probability theory</strong> [<a
target="_blank" rel="noopener" href="https://mbernste.github.io/posts/self_info/">part1</a>, <a
target="_blank" rel="noopener" href="https://mbernste.github.io/posts/measure_theory_2/">part2</a>, <a
target="_blank" rel="noopener" href="https://mbernste.github.io/posts/measure_theory_3/">part3</a>]</p>
<p>Edwin Chen. <strong>Layman's Introduction to Measure Theory</strong>
[<a
target="_blank" rel="noopener" href="https://blog.echen.me/2011/03/14/laymans-introduction-to-measure-theory/">link</a>]</p>
<p>Ales Cerný. <strong>Mathematical Techniques in Finance: Tools for
Incomplete Markets - Second Edition</strong></p>
<h2 id="blogs">blogs</h2>
<p>⭐ Prof. Dr. Maxim Ulrich, KIT. <strong>Stochastic Calculus:
Basics</strong> [<a
target="_blank" rel="noopener" href="https://youtube.com/playlist?list=PLyQSjcv8LwAEdNgdVnNH02-JTJfrwCt81">https://youtube.com/playlist?list=PLyQSjcv8LwAEdNgdVnNH02-JTJfrwCt81</a>]</p>
<p>⭐ Lewis Smith. <strong>Itô and Stratonovich; a guide for the
perplexed</strong> [<a
target="_blank" rel="noopener" href="https://www.robots.ox.ac.uk/~lsgs/posts/2018-09-30-ito-strat.html">https://www.robots.ox.ac.uk/~lsgs/posts/2018-09-30-ito-strat.html)</a>]</p>
<p>布朗运动、伊藤引理、BS 公式（前篇） [<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38293827">https://zhuanlan.zhihu.com/p/38293827</a>]</p>
<p>Wiener Process <span class="math inline">\(dB^2=dt\)</span> [<a
target="_blank" rel="noopener" href="https://math.stackexchange.com/q/81865/1059887">https://math.stackexchange.com/q/81865/1059887</a>]</p>
<p>Professor Steve Lalley Statistics 385: Brownian Motion and Stochastic
Calculus Fall 2016 [<a
target="_blank" rel="noopener" href="https://galton.uchicago.edu/~lalley/Courses/385/">https://galton.uchicago.edu/~lalley/Courses/385/</a>]</p>
<p>18.S096 | Fall 2013 | Undergraduate MIT. Topics In Mathematics With
Applications In Finance [<a
target="_blank" rel="noopener" href="https://ocw.mit.edu/courses/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/pages/syllabus/">https://ocw.mit.edu/courses/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/pages/syllabus/</a>]</p>
<p>Mathuranathan, Power and Energy of a Signal : Demystified URL: <a
target="_blank" rel="noopener" href="https://www.gaussianwaves.com/2013/12/power-and-energy-of-a-signal/">https://www.gaussianwaves.com/2013/12/power-and-energy-of-a-signal/</a></p>
<p>White Noise : Simulation and Analysis using Matlab gaussianwaves.com
[<a
target="_blank" rel="noopener" href="https://www.gaussianwaves.com/2013/11/simulation-and-analysis-of-white-noise-in-matlab/">https://www.gaussianwaves.com/2013/11/simulation-and-analysis-of-white-noise-in-matlab/)</a>]</p>
<p>Prof. J. Nathan Kutz AMATH 568 Advanced Differential Equations:
Asymptotics &amp; Perturbations [<a
target="_blank" rel="noopener" href="https://faculty.washington.edu/kutz/am568/am568.html">https://faculty.washington.edu/kutz/am568/am568.html</a>]</p>
<p>Asymptotics and perturbation methods - Prof. Steven Strogatz [<a
target="_blank" rel="noopener" href="https://youtube.com/playlist?list=PL5EH0ZJ7V0jV7kMYvPcZ7F9oaf_YAlfbI">https://youtube.com/playlist?list=PL5EH0ZJ7V0jV7kMYvPcZ7F9oaf_YAlfbI)</a>]
via <span class="citation" data-cites="YouTube">@YouTube</span></p>
<p>Simo Särkkä and Arno Solin (2014). <strong>Applied Stochastic
Differential Equations</strong>. <em>Lecture notes of the course
Becs-114.4202 Special Course in Computational Engineering II held in
Autumn 2014</em>. (<a
target="_blank" rel="noopener" href="https://users.aalto.fi/~ssarkka/course_s2014/sde_course_booklet.pdf">Booklet
as PDF</a>, <a
target="_blank" rel="noopener" href="https://users.aalto.fi/~ssarkka/course_s2014/">Slides and
exercises</a>). (2012 material is <a
target="_blank" rel="noopener" href="https://users.aalto.fi/~ssarkka/course_s2012/pdf/">here</a>).</p>
<p>Ben Chugg. Itô Integral: Construction and Basic Properties [<a
target="_blank" rel="noopener" href="https://benchugg.com/research_notes/intro_ito/">https://benchugg.com/research_notes/intro_ito/</a>]</p>
<p>Ben Chugg. Itô Processes and The Fundamental Theorem of Stochastic
Calculus [<a
target="_blank" rel="noopener" href="https://benchugg.com/research_notes/sde_ito_lemma/">https://benchugg.com/research_notes/sde_ito_lemma/)</a>]</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/09/29/network/" rel="prev" title="Network Analysis">
                  <i class="fa fa-angle-left"></i> Network Analysis
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/10/05/varstat/" rel="next" title="variables with statistical distribution">
                  variables with statistical distribution <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Guo</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.1/dist/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.3.0/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
